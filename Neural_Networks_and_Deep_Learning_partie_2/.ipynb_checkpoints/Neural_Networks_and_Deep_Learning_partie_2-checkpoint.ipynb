{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cours n° 1 : semaine 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons maintenant le cas de la régression logistique qui est en fait un très petit réseau de neurones !\n",
    "\n",
    "Si on considère un jeu de données de type image, on va être capable de prédire si une image  est celle d’un chat. En effet, pour cela il suffit de savoir qu’une image en termes de données revient à la définir sous la forme de 3 matrices d’intensités de couleurs :\n",
    "- un tableau de dimension « nombre de pixels » x « nombre de pixels » pour les couleurs Rouge (Red = R)\n",
    "- un tableau de dimension « nombre de pixels » x « nombre de pixels » pour les couleurs vertes (Green = G)\n",
    "- un tableau de dimension « nombre de pixels » x « nombre de pixels » pour les couleurs bleues (Blue = B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/representation_image.png\" style=\"width:700px;height:400;\">\n",
    "<caption><center> <u> **Figure 4** </u>: **représentation des données d’une image**<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut formaliser l’expression de la régression logistique pour une seule observation par :\n",
    "\n",
    "$\\hat{Y} = p(Y = 1 | X)$\n",
    "\n",
    "$\\hat{Y} = \\sigma(w^Tx + b)$ avec w vecteur réel de dimension nx et x vecteur réel de dimension nx<br>\n",
    "avec $\\sigma$ qui désigne la fonction sigmoïde.\n",
    "\n",
    "En connaissant ce formalisme, on peut l’appliquer à n’importe quelle observation (i), on a alors : \n",
    "$\\hat{Y} = \\sigma(w^Tx + b)$<br>\n",
    "\n",
    "On considère le vecteur $\\theta = \\begin{bmatrix} \\theta_{₀} \\\\ \n",
    "                                                  \\theta_{1} \\\\\n",
    "                                                   \\vdots\\\\\n",
    "                                                  \\theta_{n_{x}} \\\\ \n",
    "                                   \\end{bmatrix} $\n",
    "sachant que le paramètre  $\\theta_{0} = b$ et $\\theta_{0}, \\theta_{1}, …, \\theta_{n_{x}}$ correspondent à $w$\n",
    "\n",
    "On peut écrire : <br>\n",
    "$\\hat{Y} = \\sigma(\\theta^Tx)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réaliser l’apprentissage des paramètres w et b, il faut définir une fonction de coût $J$ qui va permettre d’estimer les paramètres w et b qui minimisent J. Cette fonction de coût est à estimer en fonction de tous les données d’apprentissage c’est-à-dire en fonction des m exemples d’apprentissage dont on dispose.<br>\n",
    "\n",
    "La fonction de coût « squared error » : <br>\n",
    "$L(\\hat{y},y) = \\frac{1}{2}(\\hat{y} - y)^{2}$ pourrait être utilisée, mais il se trouve que cette fonction de coût n’est pas adaptée lorsqu’elle est associée à l’algorithme gradient descent, car elle est non convexe et conduit à l’obtention de plusieurs minimums locaux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cas d’une régresssion logistique, c’est plutôt la fonction de coût de type « cross entropy » qui est utilisée : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L(\\hat{y},y) =  - (y log(\\hat{y}) + (1 - y) log(1 - \\hat{y}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction de coût convexe associée à l’algorithme « gradient descent » va permettre d’obtenir un minimum local qui va être global.\n",
    "\n",
    "On peut remarquer que si on considère la fonction de coût « cross entropy » pour une observation :\n",
    "\n",
    "- si une valeur observée y = 1, minimiser la fonction de coût implique que ŷ soit le plus proche possible de 1\n",
    "- si une valeur observée y = 0, minimiser la fonction de coût implique que ŷ soit le plus proche possible de 0\n",
    "\n",
    "Et pour $m$ observations la fonction de coût $J$ va s’écrire :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J = -\\frac{1}{m}\\sum_{i=1}^m y^{(i)}log(\\hat{y}^{(i)}) + (1 - y^{(i)}) log(1 - \\hat{y}^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposons que nous avons une seule observation (i) et que nous avons seulement 2 features, le modèle va s’écrire :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{y} = \\sigma(w_₁x_₁ + w_2x_2 + b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut définir : $z = w_₁x_₁ + w_2x_2 + b$ et l’activation : $a = \\sigma(z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variation de la fonction de coût $L$ pour une seule observation par rapport  à $z$ peut se définir par :\n",
    "$dz = \\frac{\\partial J}{\\partial z}  =  \\frac{\\partial J}{\\partial a}\\frac{\\partial a}{\\partial z}$<br>\n",
    "Comme l’expression de la fonction de coût est :<br>\n",
    "$L = -y log(a) - (1 - y) log(1 - a)$<br>\n",
    "$\\frac{\\partial L}{\\partial a} = -\\frac{y}{a} + \\frac{(1 - y)}{(1-a)} $<br>\n",
    "Et : <br>\n",
    "$\\frac{\\partial a}{\\partial z} = \\sigma^{'}(z) = \\sigma(z)(1 - \\sigma(z)) = a(1-a)$<br>\n",
    "D’où :<br>\n",
    "$dz = a - y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a aussi : <br>\n",
    "$dw_₁ = \\frac{\\partial L}{\\partial w_1} = \\frac{\\partial L}{\\partial z}\\frac{\\partial z}{\\partial w_1} = dz \\cdot x_1$<br>\n",
    "$dw_₂ = \\frac{\\partial L}{\\partial w_2} = \\frac{\\partial L}{\\partial z}\\frac{\\partial z}{\\partial w_2} = dz \\cdot x_2$<br>\n",
    "$db =  \\frac{\\partial L}{\\partial z}\\frac{\\partial z}{\\partial b} = dz \\cdot 1 = dz$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on procédera à une mise à jour des paramètres grâce à :<br>\n",
    "\n",
    "- $w₁ = w_1 - \\alpha \\cdot dw_1$\n",
    "- $w₂ = w_2 - \\alpha \\cdot dw_2$\n",
    "- $b = b - \\alpha \\cdot db$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’algorithme du gradient descent permet d’estimer les paramètres $w$ et $b$ qui minimisent la fonction de coût $J$. <br>\n",
    "Ci-dessous les étapes importantes de cet algorithme sachant que le but est de connaître les expressions de $\\frac{\\partial J}{\\partial w_1}$, $\\frac{\\partial J}{\\partial w_2}$ et $\\frac{\\partial J}{\\partial b}$, c’est-à-dire les expressions des gradients de $J$ par rapport aux paramètres à estimer du modèle. Le but ici n’est pas de calculer directement les dérivées de $J$ mais d’utiliser les expressions simplifiées trouvées précédemment pour une seule observation dans le cas de m observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel, les étapes du gradient descent sont :\n",
    "\n",
    "1. Initialisation des paramètres à zéro ou à des valeurs aléatoires\n",
    "2. Pour chaque itération, tant que $J$ décroît :\n",
    "\t- calcul de $J$ en fonction des données observées, connaissant la prédiction pour chaque observation \n",
    "\t- calcul du gradient de $J$ par rapport aux paramètres à estimer\n",
    "\t- Mise à jour des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que l’algorithme atteint des valeurs des gradients proches de zéro, on dit que l’algorithme converge. Les valeurs des paramètres obtenues sont alors les valeurs estimées.\n",
    "\n",
    "Astuce : $J = \\frac{1}{m}$ * somme des m fonctions de coût de chaque observation<br>\n",
    "Donc :<br> $\\frac{\\partial J}{\\partial w_1} = \\frac{1}{m}$ * somme des $m$ dérivées $\\frac{\\partial L}{\\partial w_1}$<br>\n",
    "$\\frac{\\partial J}{\\partial w_2} = \\frac{1}{m}$ * somme des $m$ dérivées$\\frac{\\partial L}{\\partial w_2}$<br>\n",
    "$\\frac{\\partial J}{\\partial b} = \\frac{1}{m}$ * somme des $m$ dérivées$\\frac{\\partial L}{\\partial b}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’algorithme s’écrit alors : \n",
    "1. Initialisation des paramètres à zéro ou à des valeurs aléatoires\n",
    "2. Pour chaque itération, tant que $J$ décroit :<br>\n",
    "$\\hspace{10mm}$pour chaque observation (i) :<br>\n",
    "\n",
    "$\\hspace{20mm}$ - calcul de $z^{(i)}$ :<br>\n",
    "$\\hspace{20mm}$ $z^{(i)} =   w_1x_1^{(i)} + w_2x_2^{(i)} + b$, d’où : $dz^{(i)} = a^{(i)}  - y^{(i)}$<br>\n",
    "$\\hspace{20mm}$  - cumul de $J$ (l’expression de $J$ sert à s’assurer de la décroissance de $J$)<br>\n",
    "$\\hspace{20mm}$  - cumul des  gradients sachant que :<br>\n",
    "$\\hspace{30mm}  dw₁ += x_1^{(i)} \\cdot dz^{(i)}$<br>\n",
    "$\\hspace{30mm}  dw₂ += x_2^{(i)} \\cdot dz^{(i)}$<br>\n",
    "$\\hspace{30mm}  db += dz^{(i)}$<br>\n",
    "\n",
    "$\\hspace{20mm}$ Mise à jour des paramètres avec :<br>\n",
    "$\\hspace{20mm}$ - $w_1 = w_1 - \\alpha \\cdot dw_1$<br>\n",
    "$\\hspace{20mm}$ - $w_2 = w_2 - \\alpha \\cdot dw_2$<br>\n",
    "$\\hspace{20mm}$ - $b = b - \\alpha \\cdot db$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATTENTION** : l’algorithme originel tel que décrit ci-dessus, présente des \"boucles for\" explicites suivant les $m$ observations et suivant les $n_x$ features. Il faudra faire de la vectorisation pour éviter ces \"boucles for\" explicites qui nécessiterait de créer des datasets temporaires énormes pour ce calcul !<br> \n",
    "Ce qui va être très important pour le Deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu’est-ce que la vectorisation ?<br>\n",
    "Exemple : plaçons nous dans le cas d’une seule observation pour le calcul de z :<br>\n",
    "$\\hspace{10mm} z = w^T x + b$\n",
    "\n",
    "Si on s’intéresse au calcul du terme $w^T x$, l’implémentation avec Python pour la version non vectorisée et celle vectorisée est différente.<br>\n",
    "La version vectorisée s’écrit une seule ligne de code Python de manière matricielle avec : « np.dot(w,x) »<br>\n",
    "La méthode vectorisée est 300 fois plus rapide, d’où l’intérêt de travailler de manière vectorisée  et ce d’autant plus qu’on travaille sur des problématiques Deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, l’importance de la GPU vs la CPU va encore permettre de diminuer les temps de calcul d’autant plus si on peut aussi paralléliser les traitements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on peut vectoriser tout l’algorithme « gradient descent » avec m observations.\n",
    "\n",
    "Cette  fois, on part de la matrice des données d’entrée $X$ qui a une écriture matricielle :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X = \\begin{bmatrix} \n",
    "| & | & ... & | \\\\ \n",
    "x^{(1)} & x^{(2)} & ... & x^{(m)} \\\\ \n",
    "| & | & ... & |  \n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "C'est une matrice de dimension $(n_x,m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice $Z$ va s'écrire:<br>\n",
    "$Z = \\begin{bmatrix} \n",
    "z^{(1)} & z^{(2)} & ... & z^{(m)} \\\\ \n",
    "\\end{bmatrix} = w^T \\cdot X + b =  \\begin{bmatrix} \n",
    "w^T x^{(1)} + b  & w^T x^{(2)} + b & ... & w^T x^{(m)} + b \\\\ \n",
    "\\end{bmatrix}$<br>\n",
    "\n",
    "A noter que : $w^T \\cdot X + b$ est une écriture matricielle, il s'agit bien d'un produit entre les matrices\n",
    "$w^T$ de dimension $(1,n_x)$ et $X$ de dimension $(n_x,m)$ puis somme avec la \"matrice\" $b$ de dimension $(1,m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec Numpy, $w^{T}X+b $ va s'écrire : Z = np.dot(W.T,X) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** <br>$b$ est un nombre réel mais Numpy pratique le « broadcasting », c’est-à-dire que chaque nombre réel $b$ va être adapté à la dimension de la matrice \"np.dot(W.T,X)\" et $b$ sera donc considéré de dimension $(1,m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice A va s’écrire : <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A = \\begin{bmatrix} \n",
    "a^{(1)} & a^{(2)} & ... & a^{(m)} \\\\ \n",
    "\\end{bmatrix} = \\sigma(Z)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec $\\sigma(Z)$ qui permet d'implémenter de manière vectorisée « forward propagation » pour m exemples en une seule étape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise aussi comme notations matricielles :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$dZ = \\begin{bmatrix} \n",
    "dz^{(1)} & dz^{(2)} & ... & dz^{(m)} \\\\ \n",
    "\\end{bmatrix}$ et $Y = \\begin{bmatrix} \n",
    "y^{(1)} & y^{(2)} & ... & y^{(m)} \\\\ \n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’algorithme « gradient descent » pour $m$ exemples d’apprentissage va s’écrire  de manière complètement vectorisée :<br>\n",
    "    on suppose ici que l’on fait 1000 itérations.<br>\n",
    "for iter in range(1000) :<br>\n",
    "$\\hspace{10mm}$ Etape \"forward propagation\" :<br>\n",
    "$\\hspace{10mm} Z =  w^T \\cdot X + b$ &emsp;Ecriture Python : Z = np.dot(W.T,X) + b<br>\n",
    "$\\hspace{10mm}$ Etape \"calcul des activations\" :<br>\n",
    "$\\hspace{10mm} A =  \\sigma(Z)$<br>\n",
    "$\\hspace{10mm} dZ =  A - Y $  &emsp;Ecriture Python : dZ = A - Y<br>\n",
    "$\\hspace{10mm}$ Etape cumul des gradients \"dw\" pour les $m$ observations puis on divise par $m$ :<br>\n",
    "$\\hspace{10mm} dw = \\frac{1}{m} X dZ^T$ &emsp;Ecriture Python : dw = (1/m).np.dot(X,dZ.T)<br>\n",
    "$\\hspace{10mm}$ Etape cumul des gradients \"db\" pour les $m$ observations puis on divise par $m$ :<br>\n",
    "$\\hspace{10mm} db = \\frac{1}{m} \\sum_{i=1}^mdz^{(i)}$ &emsp;Ecriture Python : db = (1/m).np.sum(dZ)<br>\n",
    "$\\hspace{10mm}$ Etape de mise à jour des poids :<br>\n",
    "$\\hspace{10mm}$ $w := w - \\alpha \\cdot dw$<br>\n",
    "$\\hspace{10mm}$ $b := b - \\alpha \\cdot db$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heroes of Deep learning** :<br>\n",
    "\n",
    "**Pieter Abbeel interview** : <br>\n",
    "Pieter Abbeel est un chercheur en Deep learning et Robotique. Il a fait beaucoup de recherches en Deep reinforcement learning notamment sur une problématique de vol autonome d’hélicoptère. Il a constaté qu’au début de ses recherches il fallait passer beaucoup de temps pour allier expertise dans le domaine de recherche à une expertise en Machine Learning. Mais en 2012, les résultats de Geoffrey Hinton pour Image Net ont montré qu’on pouvait faire de l’apprentissage supervisé avec moins d’expertise métier. Mais on doit se poser beaucoup plus de questions avec le reinforcement learning qu’avec le supervised learning. Il y a beaucoup de challenges avec le reinforcement learning, par exemple comment on pourrait apprendre pour un horizon très grand comme sur plusieurs heures ou plusieurs jours. D’autres challenges concernent l’apprentissage afin qu’il reste sécurisé et aussi comment on robot pourrait apprendre mieux qu’un humain ? Selon lui il y a beaucoup de cours en ligne intéressants, comme celui de Deep learning d’Andrej Karpathy. Berkeley propose des cours en ligne sur le reinforcement learning. Et il pense qu’il faut pratiquer, utiliser Tensorflow, Chainer, Theano, Pytorch,…. Et selon lui, il est facile d’obtenir quelque chose très rapidement. \n",
    "Enfin, pour la mise en place de cas réels et pratiques, le reinforcement learning ne peut être utilisé au départ qu’après une phase d’utilisation du Machine learning capable de mimer, cloner le comportement humain puis le reinforcement learning serait à déployer de manière à être capable de prédire à long terme."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
